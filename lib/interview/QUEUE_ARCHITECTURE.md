# Multi-Queue Interview Architecture

## Overview
This document describes the multi-queue architecture for the technical interview system, implementing a sophisticated control flow with video processing integration, technical depth progression, and intelligent follow-up mechanisms.

## Queue Structure

### Queue 0: Video Input Queue (Optional)
**Purpose:** Monitor candidate behavior and trigger interventions
**Priority:** HIGHEST - Always checked first

**Fields:**
- `use_video_processing: boolean` - Whether video monitoring is enabled
- `violation_count: number` - Count of sustained proctoring violations
- `mood_state: string` - Current detected mood (e.g., "happy", "sad", "anxious", "neutral")
- `logs: VideoLog[]` - History of video processing events

**Behavior:**
1. **Highest Priority:** Checked before every question
2. **Auto-Termination:** If `violation_count >= 3`, interview ends immediately
3. **Mood-Based Follow-ups:** When mood changes from neutral, generates empathetic follow-up in Queue 3
4. **Passive Mode:** If `use_video_processing == false`, logs are stored but no actions taken

**Example Use Cases:**
- Candidate looks away repeatedly → violation_count increments → interview ends at 3
- Candidate shows anxiety → mood follow-up: "Would you like me to rephrase the question?"
- Multiple people detected → violation logged

### Queue 1: Base Question Queue
**Purpose:** Main question pool with balanced technical/non-technical distribution

**Characteristics:**
- Contains both technical and non-technical questions
- **Randomized order** (no fixed sequence)
- **Always starts** with an intro question ("Tell me about yourself")
- **Always ends** with a wrap-up question ("Any questions for us?")
- **Non-technical limit:** ≤ 20% of total questions (excluding intro/outro)
- Each technical question has a unique `topicId` for tracking

**Structure:**
```typescript
{
  id: "q_xyz",
  question: "What is React.js?",
  category: "technical",
  answer: "React.js is a JavaScript library...",
  topicId: "topic_what_is_react_abc"
}
```

**Flow Priority:** Processed after Queue 3

### Queue 2: Technical Depth Queue
**Purpose:** Store medium and hard variants for technical questions

**Characteristics:**
- Only contains technical questions
- Each question has `difficulty: "medium" | "hard"`
- Linked to parent question via `topicId`
- Not directly asked - questions promoted to Queue 1 based on performance

**Structure:**
```typescript
{
  id: "q_abc",
  question: "Explain React Fiber architecture",
  category: "technical",
  difficulty: "hard",
  answer: "React Fiber is a reimplementation...",
  topicId: "topic_what_is_react_abc", // Same as parent
  parentQuestion: "What is React.js?"
}
```

**Promotion Rules:**
- Base question (≥80%) → Medium question moves to Queue 1
- Medium question (≥80%) → Hard question moves to Queue 1

### Queue 3: Follow-Up Queue
**Purpose:** Immediate intervention for specific scenarios

**Priority:** HIGHEST among question queues (asked before Queue 1)

**Triggers:**
1. **Low Correctness (≤10%):** Wrong answer follow-up
2. **Non-technical Follow-up:** Weak non-technical answer
3. **Mood-Based:** Generated by Queue 0 when mood changes
4. **Termination Request:** User says "I want to end this interview"

**Characteristics:**
- After a follow-up for a topic, **all Queue 2 questions for that topic are discarded**
- Follow-ups are `category: "followup"` or can be `"mood-triggered"`
- Linked to parent question for context

**Example:**
```typescript
// After wrong answer to "What is React.js?"
{
  id: "q_followup_123",
  question: "Can you tell me what you understand about JavaScript libraries in general?",
  category: "followup",
  topicId: "topic_what_is_react_abc",
  parentQuestion: "What is React.js?"
}
```

## Control Flow Rules

### Technical Question Flow
```
Ask Base Question
    ↓
Analyze Answer
    ↓
    ├─ Correctness ≤ 10%
    │   └→ Add follow-up to Queue 3
    │      └→ DISCARD all Queue 2 questions for this topic
    │
    ├─ Correctness 10-80%
    │   └→ Continue to next question (no depth progression)
    │
    └─ Correctness ≥ 80%
        └→ If base question: Move MEDIUM to Queue 1
        └→ If medium question: Move HARD to Queue 1
```

### Non-Technical Question Flow
```
Ask Non-Technical Question
    ↓
Analyze Answer
    ↓
    ├─ Correctness ≤ 10%
    │   └→ Add clarifying follow-up to Queue 3
    │
    └─ Otherwise
        └→ Continue to next question
```

### Video Processing Flow (Queue 0)
```
Before Each Question
    ↓
Check Queue 0
    ↓
    ├─ violation_count >= 3
    │   └→ END INTERVIEW IMMEDIATELY
    │
    ├─ mood_state changed && != "neutral"
    │   └→ Generate mood-based follow-up in Queue 3
    │
    └─ use_video_processing == false
        └→ Log only, no action
```

### Termination Flow
```
User Answer Contains "end this interview"
    ↓
Add final follow-up to Queue 3:
"Before we conclude, anything to clarify?"
    ↓
Ask that follow-up
    ↓
END INTERVIEW
```

## Question Priority Order

**Priority (High to Low):**
1. **Queue 0 Check** (violations/mood) - Always first
2. **Queue 3** (Follow-ups) - Immediate interventions
3. **Queue 1** (Base questions) - Main flow

**Note:** Queue 2 never directly asked - questions promoted to Queue 1

## No Repetition Rule

- Each question tracked by `topicId` or full question text
- Once asked, question marked in `askedTopics` Set
- Before asking, check if already asked → skip if duplicate
- Prevents same question appearing multiple times

## Data Model: Question Entry

When a question is asked and answered, store with these fields:

```typescript
{
  question_text: string;           // The question asked
  user_answer: string;             // User's response
  ideal_answer?: string;           // Expected/correct answer
  correctness_score?: number;      // 0-100
  source_urls?: string[];          // Reference materials
  question_type: "technical" | "non-technical" | "followup" | "mood-triggered";
  queue_number: 0 | 1 | 2 | 3;    // Which queue it came from
  timestamp: Date;                 // When asked
  
  // Queue 0 specific (if video processing active)
  mood_state?: string;             // Mood at time of question
  violation_snapshot?: {
    violation_count: number;
    current_violations: string[];  // Active violations
  }
}
```

## Implementation Files

### Core Engine
- `lib/interview/types.ts` - Type definitions for all queues
- `lib/interview/engine.ts` - Core queue processing logic
- `lib/interview/useInterviewEngine.ts` - React hook interface

### Actions & Adapters
- `app/assessment/technical-interview/actions.ts` - Server-side queue operations
- `app/assessment/technical-interview/adapter.ts` - Engine adapter implementation

### Utilities
- `utils/interview.ts` - Queue utilities (randomization, ID generation)
- `lib/interview/videoQueueIntegration.ts` - Queue 0 integration layer
- `ai-engine/prompts/technicalInterview.ts` - AI prompt builders

### Models
- `models/technicalInterviewEvaluation.model.ts` - Database schema for entries

## Usage Example

```typescript
import { useInterviewEngine } from "@/lib/interview/useInterviewEngine";
import { technicalInterviewAdapter } from "@/app/assessment/technical-interview/adapter";
import { updateVideoState, getVideoState } from "@/lib/interview/videoQueueIntegration";

// Initialize with video processing enabled
const engine = useInterviewEngine(technicalInterviewAdapter, true);

// Before asking each question
const shouldEnd = await engine.checkQueue0();
if (shouldEnd) {
  // End interview due to violations
  return;
}

// Ask next question
const question = await engine.askNext();

// User provides answer
const userAnswer = "React is...";

// Analyze and update queues
const result = await engine.handleAnswer(
  question.question,
  question.answer || "",
  userAnswer,
  question
);

// Persist to database
await engine.adapter.persistQA(interviewId, {
  question_text: question.question,
  user_answer: userAnswer,
  ideal_answer: question.answer,
  correctness_score: result.correctness,
  question_type: question.category,
  queue_number: 1, // or appropriate queue
  timestamp: new Date(),
  mood_state: engine.queues.queue0?.mood_state,
  violation_snapshot: getViolationSnapshot()
});
```

## Video Integration

### Updating Video State
From your video processing component (`video-processing.tsx`):

```typescript
import { updateVideoState } from "@/lib/interview/videoQueueIntegration";

// When mood/violations detected
updateVideoState({
  mood: "anxious",
  gesture: "looking_away",
  objects: ["person", "phone"] // Multiple objects = violation
});
```

### Integration Points
1. **Video component** calls `updateVideoState()` when detections occur
2. **Engine** calls `checkQueue0()` before each question
3. **Violations** automatically tracked and trigger interview end at 3
4. **Mood changes** automatically generate empathetic follow-ups

## Benefits

1. **Intelligent Adaptation:** System responds to candidate performance in real-time
2. **Depth Progression:** Strong candidates get harder questions on topics they know
3. **Safety Net:** Weak answers trigger clarifying follow-ups instead of failing silently
4. **Proctoring Integration:** Video violations automatically managed
5. **Empathetic Experience:** Mood detection allows supportive interventions
6. **No Repetition:** Questions never asked twice
7. **Balanced Content:** Maintains proper technical/non-technical ratio
8. **Flexible Structure:** Randomized but with guaranteed intro/outro

## Future Enhancements

- **Adaptive Difficulty:** Adjust question difficulty based on overall performance
- **Topic Clustering:** Group related questions for better flow
- **Time Management:** Prioritize questions based on remaining time
- **Performance Prediction:** Use early answers to predict final score
- **Custom Rubrics:** Topic-specific scoring weights
